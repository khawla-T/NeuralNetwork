{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khawla-T/NeuralNetwork/blob/main/sudidialect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5QqmwmB56g1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "fields=['Tweet_ID','Tweets_withDecodedemojis','Final_Annotation']\n",
        "test_dataset = pd.read_csv('tweetArabic.csv',usecols=fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVl-jREwENVL"
      },
      "outputs": [],
      "source": [
        "test_dataset_tok= Tokenizer(split=',',char_level=True, oov_token=True)\n",
        "\n",
        "test_dataset_tok.fit_on_texts(test_dataset)\n",
        "print(test_dataset_tok)\n",
        "test_dataset_sequences=test_dataset_tok.texts_to_sequences(test_dataset)\n",
        "print(test_dataset_sequences)\n",
        "print(test_dataset_tok.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVhiNDGj693y"
      },
      "outputs": [],
      "source": [
        "pip install arabert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13RRC2m8A98V"
      },
      "outputs": [],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIgbfskQ8v0F"
      },
      "source": [
        "Preprocessing\n",
        "\n",
        "Before training the model, the data is preprocessed by performing the following steps:\n",
        "\n",
        "drop all word or letters, which are not Arabic (like tags,..)\n",
        "remove repetitive letters and word which have one letter\n",
        "apply arabert preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eUR992YA87E"
      },
      "outputs": [],
      "source": [
        "from arabert import ArabertPreprocessor\n",
        "from arabert.aragpt2.grover.modeling_gpt2 import GPT2LMHeadModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RH9y2PXEBPIt"
      },
      "outputs": [],
      "source": [
        "test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlXkmPJ2BJEi"
      },
      "outputs": [],
      "source": [
        "from arabert.preprocess import ArabertPreprocessor\n",
        "\n",
        "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "\n",
        "text = test_dataset\n",
        "pros_tex = arabert_prep.preprocess(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RYqOH3yEge5"
      },
      "outputs": [],
      "source": [
        "pros_tex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5VOAyOgEzoS"
      },
      "outputs": [],
      "source": [
        "test_d= test_dataset['Tweets_withDecodedemojis']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2MegkrrFPpH",
        "outputId": "7c3c5840-5665-440a-8527-3afdb93dc905"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2023-11-03 21:30:02,074 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "\n",
        "text = test_d[0]\n",
        "pros_tex = arabert_prep.preprocess(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "S3fj_3eTFVdo",
        "outputId": "e96f3fa1-1a75-4e4a-f9ce-9ca23dda9fab"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'نعم من علام +ات ال+ جمال تلك ال+ طيبه التي ل+ اترى بل ال+ عين و+ لكن +ها تلمس ال+ قلب هذا هو ال+ جمال الذي لايشيخ أبد +ا مساء ال+ خير +ات على كل من يحب ال+ سلام و+ ال+ خير رب +ي يحفظ +كم'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pros_tex"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start Pre-processing"
      ],
      "metadata": {
        "id": "IeA6mtiZN3sg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh_-BNW1Fwy6"
      },
      "outputs": [],
      "source": [
        "fields=['Tweet_ID','Tweets_withDecodedemojis','Final_Annotation']\n",
        "train_dataset = pd.read_csv('SaudiIrony.csv',usecols=fields)\n",
        "train_d= train_dataset['Tweets_withDecodedemojis']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tunisain\n",
        "fields=['texts','data_labels']\n",
        "train_dataset_tuii = pd.read_csv('tun.csv',usecols=fields)\n",
        "train_dataset_tu=train_dataset_tuii['texts']"
      ],
      "metadata": {
        "id": "RC-KszPEu8mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_tu[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5ok_bfCu5no8",
        "outputId": "d8bf7210-e753-4237-f712-b1784f15d4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' هذا عام ينقصي أعمارنا وعام يقبل علينا فماذا فعلنا مضى وماذا سنفعل يقدم علينا  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#algirian\n",
        "fields=['id','text']\n",
        "train_dataset_al = pd.read_csv('datasetAlger.csv',usecols=fields)\n",
        "train_d_al=train_dataset_al['text']"
      ],
      "metadata": {
        "id": "o0tglYb12jWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_d_al[7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1eva0bJx54DB",
        "outputId": "34a24725-271e-4ccf-f004-12100c9b3742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'مبهمه وغامضه لم تشدني ابدا ولم اشعر بالتشويق فيها انهيتها ولا زلت انتظر المزيد '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#egypt\n",
        "fields=['review']\n",
        "train_dataset_eg = pd.read_csv('40000-Egyptian-tweets.csv',usecols=fields)\n",
        "train_d_eg=train_dataset_eg['review']"
      ],
      "metadata": {
        "id": "1Gkxlb4S3DzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_d_eg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilp867p7580s",
        "outputId": "fbf7cfb1-1387-4e38-84b3-af1bf320d968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_d_eg\n",
        "train_d_al\n",
        "train_dataset_tu"
      ],
      "metadata": {
        "id": "WGtKXFav5d3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- frequent words removing"
      ],
      "metadata": {
        "id": "VYA2fxixN_5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freq_words_removal(text, lst_words):\n",
        "    lst_text = text.split()\n",
        "    if lst_words is not None:\n",
        "        lst_text = [word for word in lst_text if word not in lst_words]\n",
        "    text = \" \".join(lst_text)\n",
        "    return text\n",
        "wrds = ['مع','لا','على','من','ما','في','الي','هو','انا','أنا','اله']\n",
        "df[\"tweet_clean\"] = df[\"tweet\"].apply(lambda x: freq_words_removal(x, wrds))"
      ],
      "metadata": {
        "id": "Id85PKXCNrUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling"
      ],
      "metadata": {
        "id": "T8gPDjstORtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Shuffle the dataset\n",
        "df = df.reindex(np.random.permutation(df.index))\n",
        "df['LABEL'] = 11 # SA is lables as 11\n",
        "dataset=dataset[dataset['dialect'].isnull()==False]"
      ],
      "metadata": {
        "id": "rOACoRF3OQ5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#One-hot encode the lab\n",
        "df.loc[df['country'] == 'SA', 'LABEL'] = 0\n",
        "# I have only one class!!\n",
        "from keras.utils.np_utils import to_categorical\n",
        "labels = to_categorical(df['LABEL'], num_classes=18)"
      ],
      "metadata": {
        "id": "NCdBF2dSOhGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDowdIwcGxFd",
        "outputId": "f78ca4c4-fd54-4888-dc3c-4b03a4bf16ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2023-11-04 10:09:05,724 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
          ]
        }
      ],
      "source": [
        "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
        "arabert_prep = ArabertPreprocessor(model_name=model_name)\n",
        "data=[]\n",
        "for l in train_d:\n",
        "    text = test_d[0]\n",
        "    pros_tex = arabert_prep.preprocess(text)\n",
        "    data.append(pros_tex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zSeFRn6HLZl",
        "outputId": "908172d3-d100-493a-e450-54c640a204b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19804"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Mu9FE_ITHkBy",
        "outputId": "033a6850-ad41-4d1e-9bc9-d504eed42e10"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'نعم من علام +ات ال+ جمال تلك ال+ طيبه التي ل+ اترى بل ال+ عين و+ لكن +ها تلمس ال+ قلب هذا هو ال+ جمال الذي لايشيخ أبد +ا مساء ال+ خير +ات على كل من يحب ال+ سلام و+ ال+ خير رب +ي يحفظ +كم'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[20]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data['dialect']='SA'\n",
        "data_dia=data\n",
        "data_dia.insert(1, \"dialect\")"
      ],
      "metadata": {
        "id": "uNGvC23CC3ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data_dia['dialect']='SA'\n",
        "data_dia[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "OVhDwMIREN1s",
        "outputId": "11a75cb8-fab9-4d09-889e-84b9d27d9e6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'نعم من علام +ات ال+ جمال تلك ال+ طيبه التي ل+ اترى بل ال+ عين و+ لكن +ها تلمس ال+ قلب هذا هو ال+ جمال الذي لايشيخ أبد +ا مساء ال+ خير +ات على كل من يحب ال+ سلام و+ ال+ خير رب +ي يحفظ +كم'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujeo4G53Hw7K"
      },
      "outputs": [],
      "source": [
        "#model_A = tf.keras.models.load_model(\"my_model_A\")\n",
        "#model_B_on_A = tf.keras.Sequential(model_A.layers[:-1])\n",
        "#model_B_on_A.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoV7c2MVx94G"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"lafifi-24/arbert_arabic_dialect_identification\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"lafifi-24/arbert_arabic_dialect_identification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpzIKnoYz6eF"
      },
      "outputs": [],
      "source": [
        "data_toknized= tokenizer(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpY83ElE0PKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01bb1922-03e7-4771-82a1-1369a78a5bbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=68, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#tokenizer.tokenize(data_toknized[3][0])\n",
        "data_toknized[3]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(data_toknized[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "t1IahCzouOAJ",
        "outputId": "f0f097f6-373e-455d-f203-70564968383c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-849722b9f240>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_toknized\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3744\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3746\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   3747\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         clean_up_tokenization_spaces = (\n",
            "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'Encoding' object cannot be converted to 'Sequence'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data_toknized\n",
        "#model\n",
        "\n",
        "new_model = tf.keras.Sequential(model.layers[:-1])\n",
        "new_model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))"
      ],
      "metadata": {
        "id": "rhN20F_w-5FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "txt = [\"فيديوات لي كيطلعو ليك فاش كتوصل لباج 987 فالموقع الازرق\"]\n",
        "seq = tokenizer.texts_to_sequences(txt)\n",
        "padded = pad_sequences(seq, maxlen=max_len)\n",
        "pred = model.predict(padded)\n",
        "labels = ['SA','QA','KW','AE','OM','JO','PL','BH','LY','EG','SD','IQ','LB','SY','TN','DZ','MA','YE']\n",
        "print(pred, labels[np.argmax(pred)])"
      ],
      "metadata": {
        "id": "N-5Q-DTeQjsd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19DzWcIk0XmWM23_kDqHVnDGDmfWlzYWS",
      "authorship_tag": "ABX9TyOQiy7GXrzU4ulWOxsCWCM0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}